{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a988c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from IPython.display import display, Image, Markdown\n",
    "# If your project is not on sys.path, add it:\n",
    "project_root = Path(\"/home/ansary/work/apsis/DocSignerNML\")\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "# Cell A: simple, notebook-friendly PDF reader\n",
    "import logging\n",
    "import io\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "try:\n",
    "    from pdf2image import convert_from_path\n",
    "    from pypdf import PdfReader, PdfWriter\n",
    "    from markitdown import MarkItDown\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"Missing dependency; run: pip install -r requirements.txt\") from e\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def extract_content_per_page(pdf_path: Path, output_dir: Path, dpi: int = 300) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert PDF pages to PNG images (saved under output_dir) and extract per-page Markdown text.\n",
    "    Returns a list of dicts: { \"page_num\": int, \"markdown_text\": str, \"image_path\": Path }.\n",
    "    Notebook-friendly: does not require FastAPI UploadFile or context manager.\n",
    "    \"\"\"\n",
    "    pdf_path = Path(pdf_path)\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(pdf_path)\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Convert PDF pages to images (returns PIL Image objects)\n",
    "    logger.info(f\"Converting {pdf_path} -> images (dpi={dpi}) into {output_dir}\")\n",
    "    pil_images = convert_from_path(str(pdf_path), dpi=dpi, fmt='png', thread_count=4)\n",
    "\n",
    "    image_paths: List[Path] = []\n",
    "    stem = pdf_path.stem\n",
    "    for i, img in enumerate(pil_images):\n",
    "        image_name = f\"{stem}_page_{i+1:03d}.png\"\n",
    "        img_path = output_dir / image_name\n",
    "        img.save(img_path, \"PNG\")\n",
    "        image_paths.append(img_path)\n",
    "\n",
    "    # 2) Extract Markdown/text per page using MarkItDown (in-memory)\n",
    "    logger.info(\"Extracting markdown/text per page (in-memory) ...\")\n",
    "    markdown_texts: List[str] = []\n",
    "    md_converter = MarkItDown()\n",
    "    reader = PdfReader(str(pdf_path))\n",
    "\n",
    "    for page in reader.pages:\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(page)\n",
    "        with io.BytesIO() as bs:\n",
    "            writer.write(bs)\n",
    "            bs.seek(0)\n",
    "            text = \"\"\n",
    "            # Try multiple interfaces of MarkItDown for compatibility\n",
    "            try:\n",
    "                if hasattr(md_converter, \"convert_stream\"):\n",
    "                    result = md_converter.convert_stream(bs)\n",
    "                    text = getattr(result, \"text_content\", None) or getattr(result, \"text\", None) or str(result)\n",
    "                elif hasattr(md_converter, \"convert_fp\"):\n",
    "                    result = md_converter.convert_fp(bs)\n",
    "                    text = getattr(result, \"text_content\", None) or getattr(result, \"text\", None) or str(result)\n",
    "                else:\n",
    "                    # fallback: give raw bytes (some MarkItDown versions accept bytes)\n",
    "                    bs.seek(0)\n",
    "                    result = md_converter.convert(bs.read())\n",
    "                    text = getattr(result, \"text_content\", None) or getattr(result, \"text\", None) or str(result)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"MarkItDown conversion failed for a page: {e}\")\n",
    "                text = \"\"\n",
    "            markdown_texts.append(text or \"\")\n",
    "\n",
    "    # safety: if mismatch, pad markdown_texts (won't crash notebook)\n",
    "    if len(image_paths) != len(markdown_texts):\n",
    "        logger.warning(\"Image/markdown count mismatch — padding markdown to match images.\")\n",
    "        if len(markdown_texts) < len(image_paths):\n",
    "            markdown_texts += [\"\"] * (len(image_paths) - len(markdown_texts))\n",
    "        else:\n",
    "            image_paths += [None] * (len(markdown_texts) - len(image_paths))\n",
    "\n",
    "    bundles = []\n",
    "    for i in range(len(image_paths)):\n",
    "        bundles.append({\n",
    "            \"page_num\": i + 1,\n",
    "            \"markdown_text\": markdown_texts[i],\n",
    "            \"image_path\": image_paths[i]\n",
    "        })\n",
    "    return bundles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56954c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b660c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 14:23:41,073 - INFO - Converting doctests/test.pdf -> images (dpi=96) into temp_files_jupyter/test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLMService (Sync) initialized for model 'RedHatAI/gemma-3-27b-it-FP8-dynamic' with max_tokens=64000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 14:23:41,698 - INFO - Extracting markdown/text per page (in-memory) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages processed: 1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from document_ai_verification.utils.config_loader import load_settings\n",
    "from document_ai_verification.ai.llm.client import LLMService\n",
    "from document_ai_verification.ai.llm.prompts import get_ns_document_analysis_prompt_holistic\n",
    "from document_ai_verification.ai.llm.schemas import PageHolisticAnalysis\n",
    "# --- Setup ---\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "APP_SETTINGS = load_settings()\n",
    "SECRETS = APP_SETTINGS['secrets']\n",
    "CONFIG = APP_SETTINGS['config']\n",
    "\n",
    "LLM_CLIENT = LLMService(\n",
    "    api_key=SECRETS['llm_api_key'],\n",
    "    model=SECRETS['llm_model_name'],\n",
    "    base_url=SECRETS['llm_api_url'],\n",
    "    max_context_tokens=CONFIG['ai_services']['llm'].get('max_context_tokens', 64000)\n",
    ")\n",
    "\n",
    "\n",
    "# Cell C: Run the reader on your PDF (quick test)\n",
    "pdf_path = Path(\"doctests/test.pdf\")\n",
    "out_dir = Path(\"./temp_files_jupyter\") / pdf_path.stem\n",
    "# small DPI for speed while testing\n",
    "bundles = extract_content_per_page(pdf_path, out_dir, dpi=96)\n",
    "print(f\"Pages processed: {len(bundles)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35daa650",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1t=bundles[0][\"markdown_text\"]\n",
    "p1i=bundles[0][\"image_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af7a502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 14:23:49,028 - INFO - Performing vision call for image: test_page_001.png\n",
      "2025-09-11 14:24:02,028 - INFO - HTTP Request: POST http://114.130.116.79/gemma3/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "prompt=get_ns_document_analysis_prompt_holistic(p1t)\n",
    "result=LLM_CLIENT.invoke_vision_structured(prompt=prompt,image_path=p1i,response_model=PageHolisticAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b35ac09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI Policy and Direction from Faiz Tayeb Sir\\n\\nI …………. Declare that I have received the summary frim tayed sir\\n\\nSummary:\\nThe Government of Bangladesh is currently developing an interoperability platform to streamline\\ncitizen services. While the platform has reached a functional stage, the integration of numerous\\nAPIs is expected to make the data exchange policy increasingly complex. Therefore, a strategic\\napproach is required to address the following key areas:\\n\\n1.  Role of AI: We must identify how Artificial Intelligence can enhance data exchange,\\nregulatory compliance, and enforcement mechanisms within this interoperability\\necosystem.\\n\\n2.  Ministerial AI Adoption Challenges: It is essential to assess the specific challenges\\nfaced by different ministries in adopting AI and determine how AI can support their\\noperations. Although UNESCO has contributed work in this area, the quality has not met\\nexpectations and requires improvement.\\n\\n3.  Cloud Infrastructure for Emerging Sectors: Consideration must be given to providing\\ncloud computing environments for emerging sectors such as ed-tech and healthcare.\\nKey questions include:\\n\\n○  Should the government offer this infrastructure? :[YOUR OPINION IN YES/NO]\\n○  What would the management and maintenance model look like?:[YOUR\\n\\nOPINION IN YES/NO]\\n\\n○  How will the translation (handover) and exit phases be handled, especially given\\nthe project-based nature of implementation in Bangladesh?:[YOUR OPINION IN\\nYES/NO]\\n\\n4.  Stakeholder Inclusion: Finally, a comprehensive and inclusive AI policy must be\\n\\ndeveloped with active participation from all stakeholders—including government bodies,\\nacademia, the private sector, and civil society—to guide AI adoption and governance in\\nBangladesh.\\n\\nSign\\n\\n---------------------\\nName:\\nCompany:\\nPosition:\\nDate:\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78b5002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'required_inputs': [{'input_type': 'checkbox',\n",
       "   'marker_text': '[YOUR OPINION IN YES/NO]',\n",
       "   'description': 'User must indicate their opinion with a yes or no checkbox.'},\n",
       "  {'input_type': 'checkbox',\n",
       "   'marker_text': '[YOUR OPINION IN YES/NO]',\n",
       "   'description': 'User must indicate their opinion with a yes or no checkbox.'},\n",
       "  {'input_type': 'checkbox',\n",
       "   'marker_text': '[YOUR OPINION IN YES/NO]',\n",
       "   'description': 'User must indicate their opinion with a yes or no checkbox.'},\n",
       "  {'input_type': 'full_name',\n",
       "   'marker_text': 'Name:',\n",
       "   'description': 'User must provide their full name.'},\n",
       "  {'input_type': 'other',\n",
       "   'marker_text': 'Company:',\n",
       "   'description': 'User must provide the company name.'},\n",
       "  {'input_type': 'other',\n",
       "   'marker_text': 'Position:',\n",
       "   'description': 'User must provide their position.'},\n",
       "  {'input_type': 'date',\n",
       "   'marker_text': 'Date:',\n",
       "   'description': 'User must provide the date.'},\n",
       "  {'input_type': 'signature',\n",
       "   'marker_text': 'Sign',\n",
       "   'description': 'User must provide their signature.'}],\n",
       " 'prefilled_inputs': [],\n",
       " 'summary': 'No fields are prefilled; Name, Company, Position, Date, Signature and three checkboxes are required.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3905c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n"
     ]
    }
   ],
   "source": [
    "a=[]\n",
    "if a:\n",
    "    print(\"C\")\n",
    "else:\n",
    "    print(\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac745427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docmlaps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
