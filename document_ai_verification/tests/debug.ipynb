{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491eaf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PWD_PATH=\"/home/ansary/WORK_archive/apsis/DocSignerNML\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd35b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from IPython.display import display, Image, Markdown\n",
    "# If your project is not on sys.path, add it:\n",
    "project_root = Path(PWD_PATH)\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a988c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cell A: simple, notebook-friendly PDF reader\n",
    "import logging\n",
    "import io\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "try:\n",
    "    from pdf2image import convert_from_path\n",
    "    from pypdf import PdfReader, PdfWriter\n",
    "    from markitdown import MarkItDown\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"Missing dependency; run: pip install -r requirements.txt\") from e\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def extract_content_per_page(pdf_path: Path, output_dir: Path, dpi: int = 300) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert PDF pages to PNG images (saved under output_dir) and extract per-page Markdown text.\n",
    "    Returns a list of dicts: { \"page_num\": int, \"markdown_text\": str, \"image_path\": Path }.\n",
    "    Notebook-friendly: does not require FastAPI UploadFile or context manager.\n",
    "    \"\"\"\n",
    "    pdf_path = Path(pdf_path)\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(pdf_path)\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Convert PDF pages to images (returns PIL Image objects)\n",
    "    logger.info(f\"Converting {pdf_path} -> images (dpi={dpi}) into {output_dir}\")\n",
    "    pil_images = convert_from_path(str(pdf_path), dpi=dpi, fmt='png', thread_count=4)\n",
    "\n",
    "    image_paths: List[Path] = []\n",
    "    stem = pdf_path.stem\n",
    "    for i, img in enumerate(pil_images):\n",
    "        image_name = f\"{stem}_page_{i+1:03d}.png\"\n",
    "        img_path = output_dir / image_name\n",
    "        img.save(img_path, \"PNG\")\n",
    "        image_paths.append(img_path)\n",
    "\n",
    "    # 2) Extract Markdown/text per page using MarkItDown (in-memory)\n",
    "    logger.info(\"Extracting markdown/text per page (in-memory) ...\")\n",
    "    markdown_texts: List[str] = []\n",
    "    md_converter = MarkItDown()\n",
    "    reader = PdfReader(str(pdf_path))\n",
    "\n",
    "    for page in reader.pages:\n",
    "        writer = PdfWriter()\n",
    "        writer.add_page(page)\n",
    "        with io.BytesIO() as bs:\n",
    "            writer.write(bs)\n",
    "            bs.seek(0)\n",
    "            text = \"\"\n",
    "            # Try multiple interfaces of MarkItDown for compatibility\n",
    "            try:\n",
    "                if hasattr(md_converter, \"convert_stream\"):\n",
    "                    result = md_converter.convert_stream(bs)\n",
    "                    text = getattr(result, \"text_content\", None) or getattr(result, \"text\", None) or str(result)\n",
    "                elif hasattr(md_converter, \"convert_fp\"):\n",
    "                    result = md_converter.convert_fp(bs)\n",
    "                    text = getattr(result, \"text_content\", None) or getattr(result, \"text\", None) or str(result)\n",
    "                else:\n",
    "                    # fallback: give raw bytes (some MarkItDown versions accept bytes)\n",
    "                    bs.seek(0)\n",
    "                    result = md_converter.convert(bs.read())\n",
    "                    text = getattr(result, \"text_content\", None) or getattr(result, \"text\", None) or str(result)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"MarkItDown conversion failed for a page: {e}\")\n",
    "                text = \"\"\n",
    "            markdown_texts.append(text or \"\")\n",
    "\n",
    "    # safety: if mismatch, pad markdown_texts (won't crash notebook)\n",
    "    if len(image_paths) != len(markdown_texts):\n",
    "        logger.warning(\"Image/markdown count mismatch — padding markdown to match images.\")\n",
    "        if len(markdown_texts) < len(image_paths):\n",
    "            markdown_texts += [\"\"] * (len(image_paths) - len(markdown_texts))\n",
    "        else:\n",
    "            image_paths += [None] * (len(markdown_texts) - len(image_paths))\n",
    "\n",
    "    bundles = []\n",
    "    for i in range(len(image_paths)):\n",
    "        bundles.append({\n",
    "            \"page_num\": i + 1,\n",
    "            \"markdown_text\": markdown_texts[i],\n",
    "            \"image_path\": image_paths[i]\n",
    "        })\n",
    "    return bundles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56954c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b660c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 11:54:44,954 - INFO - Converting doctests/test.pdf -> images (dpi=96) into temp_files/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 11:54:45,145 - INFO - Extracting markdown/text per page (in-memory) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLMService (Sync) initialized for model 'RedHatAI/gemma-3-27b-it-FP8-dynamic' with max_tokens=64000.\n",
      "Pages processed: 1\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "from document_ai_verification.utils.config_loader import load_settings\n",
    "from document_ai_verification.ai.llm.client import LLMService\n",
    "from document_ai_verification.ai.llm.prompts import get_ns_document_analysis_prompt_holistic\n",
    "from document_ai_verification.ai.llm.schemas import PageHolisticAnalysis\n",
    "# --- Setup ---\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "APP_SETTINGS = load_settings()\n",
    "SECRETS = APP_SETTINGS['secrets']\n",
    "CONFIG = APP_SETTINGS['config']\n",
    "\n",
    "LLM_CLIENT = LLMService(\n",
    "    api_key=SECRETS['llm_api_key'],\n",
    "    model=SECRETS['llm_model_name'],\n",
    "    base_url=SECRETS['llm_api_url'],\n",
    "    max_context_tokens=CONFIG['ai_services']['llm'].get('max_context_tokens', 64000)\n",
    ")\n",
    "\n",
    "\n",
    "# Cell C: Run the reader on your PDF (quick test)\n",
    "pdf_path = Path(\"doctests/test.pdf\")\n",
    "out_dir = Path(\"./temp_files\") / pdf_path.stem\n",
    "# small DPI for speed while testing\n",
    "bundles = extract_content_per_page(pdf_path, out_dir, dpi=96)\n",
    "print(f\"Pages processed: {len(bundles)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35daa650",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1t=bundles[0][\"markdown_text\"]\n",
    "p1i=bundles[0][\"image_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7a502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-15 11:55:05,510 - INFO - Performing vision call for image: test_page_001.png\n",
      "2025-09-15 11:55:28,317 - INFO - HTTP Request: POST http://114.130.116.79/gemma3/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "prompt=get_ns_document_analysis_prompt_holistic(p1t)\n",
    "result=LLM_CLIENT.invoke_vision_structured(prompt=prompt,image_path=p1i,response_model=PageHolisticAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78b5002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'required_inputs': [{'input_type': 'checkbox',\n",
       "   'marker_text': 'Should the government offer this infrastructure?:[YOUR OPINION IN YES/NO]',\n",
       "   'description': 'User must indicate their opinion with a Yes/No response.'},\n",
       "  {'input_type': 'checkbox',\n",
       "   'marker_text': 'What would the management and maintenance model look like?:[YOUR OPINION IN YES/NO]',\n",
       "   'description': 'User must indicate their opinion with a Yes/No response.'},\n",
       "  {'input_type': 'checkbox',\n",
       "   'marker_text': 'How will the translation (handover) and exit phases be handled, especially given the project-based nature of implementation in Bangladesh?:[YOUR OPINION IN YES/NO]',\n",
       "   'description': 'User must indicate their opinion with a Yes/No response.'},\n",
       "  {'input_type': 'full_name',\n",
       "   'marker_text': 'Name:',\n",
       "   'description': 'User must provide their full name.'},\n",
       "  {'input_type': 'other',\n",
       "   'marker_text': 'Company:',\n",
       "   'description': 'User must provide their company name.'},\n",
       "  {'input_type': 'other',\n",
       "   'marker_text': 'Position:',\n",
       "   'description': 'User must provide their position/title.'},\n",
       "  {'input_type': 'date',\n",
       "   'marker_text': 'Date:',\n",
       "   'description': 'User must provide the date.'},\n",
       "  {'input_type': 'signature',\n",
       "   'marker_text': 'Sign',\n",
       "   'description': 'User must provide a signature.'}],\n",
       " 'prefilled_inputs': [],\n",
       " 'summary': 'All fields require user input, including name, company, position, date, and signature. The opinion checkboxes also need to be answered.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac745427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- USER'S ORIGINAL COMMENTED CODE FOR STAGE 2/3 - PRESERVED ---\n",
    "            # # --- 3. Page-by-Page Multi-Modal Audit ---\n",
    "            # logger.info(\"Phase 2: Performing page-by-page multi-modal audit...\")\n",
    "            # for page_num in range(1, len(nsv_page_bundles) + 1):\n",
    "            #     page_meta={}\n",
    "            #     nsv_bundle = nsv_page_bundles[page_num - 1]\n",
    "            #     sv_bundle = sv_page_bundles[page_num - 1]\n",
    "            #     page_requirements = requirements_map[page_num].model_dump()\n",
    "\n",
    "            #     # --- 3a. Gather the Evidence Inputs ---\n",
    "            #     sv_markdown = sv_bundle['markdown_text']\n",
    "            #     nsv_markdown = nsv_bundle['markdown_text']\n",
    "            #     nsv_image_path = sv_bundle['image_path']\n",
    "            #     sv_image_path = sv_bundle['image_path']\n",
    "                    \n",
    "            #     page_meta[\"page_num\"]=page_num\n",
    "                \n",
    "            #     # if we do not have markdown\n",
    "            #     if not sv_markdown or not sv_markdown.strip():\n",
    "            #         page_meta[\"sv_type\"]=\"scanned\"\n",
    "            #         logger.info(f\"Page {page_num} of SV appears scanned. Using OCR...\")\n",
    "            #         try:\n",
    "            #             sv_content = extract_text_from_image(sv_image_path, api_url=SECRETS['ocr_url']).plain_text\n",
    "            #             nsv_content =extract_text_from_image(nsv_image_path, api_url=SECRETS['ocr_url']).plain_text\n",
    "            #         except OcrAPIError:\n",
    "            #             logger.info(\"OCR API NOT WORKING\")\n",
    "            #     else:\n",
    "            #         page_meta[\"sv_type\"]=\"digital\" \n",
    "            #         sv_content=sv_markdown\n",
    "            #         nsv_content=nsv_markdown\n",
    "\n",
    "            #     # ---------- handle digital documents -----------------\n",
    "            #     if page_meta[\"sv_type\"]==\"digital\":\n",
    "            #         try:\n",
    "            #             nsv_img = cv2.imread(str(nsv_image_path))\n",
    "            #             sv_img = cv2.imread(str(sv_image_path))\n",
    "            #             page_meta=analyze_page_meta_from_image(nsv_img,sv_img,page_meta)\n",
    "            #             if not page_requirements['required_inputs'] and page_meta[\"difference\"] and page_meta[\"content\"]==\"not_matching\":\n",
    "            #                 yield  nsv_img,sv_img,page_meta\n",
    "            #                 raise ContentMismatchError(\"Content Mismatch Found\")\n",
    "            #         except Exception as e:\n",
    "            #             logger.error(f\"Could Not Read and process images:{e}\")\n",
    "            #     else:\n",
    "            #         page_meta[\"source\"] = \"not_matching\"\n",
    "                \n",
    "            #     # --- 3b. Execute the Final Audit with the VLLM ---\n",
    "            #     # ... (rest of commented code) ...\n",
    "\n",
    "            # --- NEW: Signal that the entire workflow (as it exists now) is complete ---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docsssmlnms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
